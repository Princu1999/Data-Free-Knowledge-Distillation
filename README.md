
# Adversarial Knowledge Distillation (AKD) with GANs — CIFAR-100

> Modular PyTorch refactor of your Colab/monolithic script into a clean, GitHub‑ready repo. > Implements **data‑free adversarial knowledge distillation** (ResNet‑34 teacher → compact students) > and a tiny generator to synthesize training stimuli.

<p align="center">
<a href="#-quickstart">Quickstart</a> •
<a href="#-project-structure">Structure</a> •
<a href="#-results">Results</a> •
<a href="#-training--evaluation">Training</a> •
<a href="#-references">References</a>
</p>

---

## Highlights
- **Teacher**: ResNet‑34 (pretrained on CIFAR‑100) distills logits to students without real training data.  
- **Students**: (i) `ResNet18_8x_Small` (~20% teacher params), (ii) `ResNet18_8x` (~50% teacher params).  
- **GeneratorA**: Lightweight GAN‑style image sampler (latent `z→32×32`) to drive KD.

## Quickstart
```bash
# 1) Install
pip install -r requirements.txt

# 2) (Optional) Place teacher weights
#    ./teacher/best_resnet34_cifar100.pth

# 3) Train + evaluate (writes run folders in ./logs, ./models, ./results)
python scripts/train_akd.py
```

To sample images from the generator:
```bash
python scripts/generate_images.py
```

## 🗂 Project Structure
```
akd_kd_gan/
  akd_kd_gan/
    __init__.py
    config.py                 # AKDConfig: paths, hparams, seeds, run folders
    data.py                   # CIFAR‑100 loader for test‑only split
    losses.py                 # KL‑KD, diversity loss (utility)
    models/
      generator.py            # GeneratorA (z→32×32)
      resnet_small.py         # BasicBlock/Bottleneck/ResNet/ResNet18_8x/_Small
    engine/
      train.py                # train_epoch() (alternate student/gen updates)
      eval.py                 # evaluate() → CE loss & accuracy
    utils/
      logger.py, early_stopping.py, checkpoint.py
  scripts/
    train_akd.py              # end‑to‑end AKD training loop (teacher→students)
    generate_images.py        # grid + individual PNGs
requirements.txt
README.md
```

## Results
Key numbers extracted from your report:

- **Accuracy (20% test split)** — Student‑50%: **39.9%**, Student‑10%: **20%**   (CIFAR‑100, teacher = ResNet‑34). fileciteturn1file1L127-L135  
- **Accuracy (10% test split)** — Student‑50%: **38.10%**, Student‑10%: **19.01%**. fileciteturn1file1L136-L141  
- **Parameter counts** — Teacher: **21,335,972**; Student‑10%: **2,820,740**; Student‑50%: **11,220,132**. fileciteturn1file9L47-L52

> The codebase mirrors your original training procedure (alternate student and generator updates and evaluation on CIFAR‑100 test subsets). fileciteturn1file3L36-L63 fileciteturn1file2L41-L45

<details>
<summary><b>Method summary (from your report)</b></summary>

- Distill teacher → students via KL on synthetic images from the generator; update generator adversarially to maximize student‑teacher gap. fileciteturn1file1L56-L61  
- Dataset is **test‑only CIFAR‑100**; original training data is not used. fileciteturn1file1L19-L22
</details>

## Training & Evaluation
- Configure defaults in `akd_kd_gan/config.py` (paths, learning rates, epochs, etc.).  
- `scripts/train_akd.py` will:
  1) build teacher (loads `./teacher/best_resnet34_cifar100.pth` if present),  
  2) train **Student‑50%** and **Student‑20%** alternating with the generator,  
  3) evaluate after each epoch and save best checkpoints to `./models/<run_id>/`.

> The refactor keeps the original generator and student update schedule (15× student steps, then 1× generator step) for parity with the notebook. fileciteturn1file3L48-L56

## Notes
- The small student architecture retains the slimmed channels you used (~20% teacher params). fileciteturn1file5L31-L46  
- Run metadata & `config.json` are automatically written under `./logs/<run_id>/` (reproducibility & audit). fileciteturn1file6L39-L50

## References
Your report lists the core AKD/KD papers (Hinton et al., Micaelli & Storkey, etc.). fileciteturn1file8L30-L48

---

> This repository was generated by refactoring your uploaded script while preserving behavior (training loop, models, and generator) and surfacing the most important results for quick understanding.
